{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import enumerate, len\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [ \"../data/df_test_1.csv\", \"../data/df_test_2.csv\"]\n",
    "ngrams = [2,3]\n",
    "repl_prod_name = [True, False]\n",
    "tokens = [\"common_tokens\", \"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    train_idxes = df.test_idx.unique()\n",
    "    print(train_idxes)\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for train_idx in train_idxes:\n",
    "        mask = df.test_idx == train_idx\n",
    "\n",
    "        df_train = pd.read_csv(path)\n",
    "        df_test = copy(df_train)\n",
    "\n",
    "        df_train = df_train[~mask]\n",
    "        df_test = df_test[mask]\n",
    "\n",
    "        res += [(df_train, df_test)]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(dataset_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5792 189 5792 189\n",
      "4591 1390 4591 1390\n",
      "4960 1021 4960 1021\n",
      "4320 1661 4320 1661\n",
      "5283 698 5283 698\n",
      "5764 217 5764 217\n",
      "5176 805 5176 805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=literal_eval)\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_train = dataset[0]\n",
    "    df_test = dataset[1]\n",
    "    \n",
    "    temp_train = vectorizer.fit_transform(df_train[\"tokens\"])\n",
    "    x_train.append(temp_train.toarray())\n",
    "    y_train.append(df_train.bool_rating.tolist())\n",
    "\n",
    "    temp_test = vectorizer.transform(df_test[\"tokens\"])\n",
    "    x_test.append(temp_test.toarray())\n",
    "    y_test.append(df_test.bool_rating.tolist())\n",
    "\n",
    "    print(len(x_train[-1]), len(x_test[-1]), len(y_train[-1]), len(y_test[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 145 tn= 19 fp= 14 fn= 11\n",
      "scoring= 0.8677248677248677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 1165 tn= 86 fp= 123 fn= 16\n",
      "scoring= 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 813 tn= 35 fp= 152 fn= 21\n",
      "scoring= 0.8305582761998042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 1386 tn= 85 fp= 141 fn= 49\n",
      "scoring= 0.8856110776640578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 561 tn= 43 fp= 76 fn= 18\n",
      "scoring= 0.8653295128939829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 183 tn= 9 fp= 10 fn= 15\n",
      "scoring= 0.8847926267281107\n",
      "tp= 618 tn= 68 fp= 112 fn= 7\n",
      "scoring= 0.8521739130434782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    clf.fit(x_train[it], y_train[it])\n",
    "    predicted = clf.predict(x_test[it])\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 4871 tn= 345 fp= 628 fn= 137\n",
      "scoring= 0.8720949673967564\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 145 tn= 28 fp= 5 fn= 11\n",
      "scoring= 0.9153439153439153\n",
      "tp= 1161 tn= 143 fp= 66 fn= 20\n",
      "scoring= 0.9381294964028777\n",
      "tp= 806 tn= 88 fp= 99 fn= 28\n",
      "scoring= 0.8756121449559255\n",
      "tp= 1361 tn= 172 fp= 54 fn= 74\n",
      "scoring= 0.9229379891631547\n",
      "tp= 561 tn= 92 fp= 27 fn= 18\n",
      "scoring= 0.9355300859598854\n",
      "tp= 193 tn= 12 fp= 7 fn= 5\n",
      "scoring= 0.9447004608294931\n",
      "tp= 617 tn= 106 fp= 74 fn= 8\n",
      "scoring= 0.8981366459627329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    clf.fit(x_train[it], y_train[it])\n",
    "    predicted = clf.predict(x_test[it])\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 4844 tn= 641 fp= 332 fn= 164\n",
      "scoring= 0.9170707239592042\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Witten Bell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_witten_bell(x):\n",
    "    print(\"start\")\n",
    "    df_x = pd.DataFrame(x)\n",
    "    print(\"iterating\")\n",
    "    res = []\n",
    "\n",
    "    for it, row in df_x.iterrows():\n",
    "        \n",
    "        if it %500 == 0:\n",
    "            print(it, x.shape)\n",
    "        N = sum(row)\n",
    "        #print(\"N\", N)\n",
    "        M = sum([1 for x in row if x != 0])\n",
    "        #print(\"M\", M)\n",
    "        row = row/row.sum()\n",
    "        nval = 1/(N+M)\n",
    "        #print(\"applying\", nval)\n",
    "        row = row.replace(0, nval)\n",
    "        #print(\"set value\")\n",
    "        res.append(row)\n",
    "        #print(\"ready with row\")\n",
    "    df_res = pd.DataFrame(res)\n",
    "\n",
    "    return df_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "iterating\n",
      "0 (5792, 9137)\n",
      "500 (5792, 9137)\n",
      "1000 (5792, 9137)\n",
      "1500 (5792, 9137)\n",
      "2000 (5792, 9137)\n",
      "2500 (5792, 9137)\n",
      "3000 (5792, 9137)\n",
      "3500 (5792, 9137)\n",
      "4000 (5792, 9137)\n",
      "4500 (5792, 9137)\n",
      "5000 (5792, 9137)\n",
      "5500 (5792, 9137)\n",
      "start\n",
      "iterating\n",
      "0 (189, 9137)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 156 tn= 0 fp= 33 fn= 0\n",
      "scoring= 0.8253968253968254\n",
      "start\n",
      "iterating\n",
      "0 (4591, 7935)\n",
      "500 (4591, 7935)\n",
      "1000 (4591, 7935)\n",
      "1500 (4591, 7935)\n",
      "2000 (4591, 7935)\n",
      "2500 (4591, 7935)\n",
      "3000 (4591, 7935)\n",
      "3500 (4591, 7935)\n",
      "4000 (4591, 7935)\n",
      "4500 (4591, 7935)\n",
      "start\n",
      "iterating\n",
      "0 (1390, 7935)\n",
      "500 (1390, 7935)\n",
      "1000 (1390, 7935)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 1181 tn= 0 fp= 209 fn= 0\n",
      "scoring= 0.8496402877697842\n",
      "start\n",
      "iterating\n",
      "0 (4960, 8068)\n",
      "500 (4960, 8068)\n",
      "1000 (4960, 8068)\n",
      "1500 (4960, 8068)\n",
      "2000 (4960, 8068)\n",
      "2500 (4960, 8068)\n",
      "3000 (4960, 8068)\n",
      "3500 (4960, 8068)\n",
      "4000 (4960, 8068)\n",
      "4500 (4960, 8068)\n",
      "start\n",
      "iterating\n",
      "0 (1021, 8068)\n",
      "500 (1021, 8068)\n",
      "1000 (1021, 8068)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 834 tn= 0 fp= 187 fn= 0\n",
      "scoring= 0.8168462291870715\n",
      "start\n",
      "iterating\n",
      "0 (4320, 7986)\n",
      "500 (4320, 7986)\n",
      "1000 (4320, 7986)\n",
      "1500 (4320, 7986)\n",
      "2000 (4320, 7986)\n",
      "2500 (4320, 7986)\n",
      "3000 (4320, 7986)\n",
      "3500 (4320, 7986)\n",
      "4000 (4320, 7986)\n",
      "start\n",
      "iterating\n",
      "0 (1661, 7986)\n",
      "500 (1661, 7986)\n",
      "1000 (1661, 7986)\n",
      "1500 (1661, 7986)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 1435 tn= 0 fp= 226 fn= 0\n",
      "scoring= 0.863937387116195\n",
      "start\n",
      "iterating\n",
      "0 (5283, 8299)\n",
      "500 (5283, 8299)\n",
      "1000 (5283, 8299)\n",
      "1500 (5283, 8299)\n",
      "2000 (5283, 8299)\n",
      "2500 (5283, 8299)\n",
      "3000 (5283, 8299)\n",
      "3500 (5283, 8299)\n",
      "4000 (5283, 8299)\n",
      "4500 (5283, 8299)\n",
      "5000 (5283, 8299)\n",
      "start\n",
      "iterating\n",
      "0 (698, 8299)\n",
      "500 (698, 8299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 579 tn= 0 fp= 119 fn= 0\n",
      "scoring= 0.829512893982808\n",
      "start\n",
      "iterating\n",
      "0 (5764, 8823)\n",
      "500 (5764, 8823)\n",
      "1000 (5764, 8823)\n",
      "1500 (5764, 8823)\n",
      "2000 (5764, 8823)\n",
      "2500 (5764, 8823)\n",
      "3000 (5764, 8823)\n",
      "3500 (5764, 8823)\n",
      "4000 (5764, 8823)\n",
      "4500 (5764, 8823)\n",
      "5000 (5764, 8823)\n",
      "5500 (5764, 8823)\n",
      "start\n",
      "iterating\n",
      "0 (217, 8823)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 198 tn= 0 fp= 19 fn= 0\n",
      "scoring= 0.9124423963133641\n",
      "start\n",
      "iterating\n",
      "0 (5176, 8431)\n",
      "500 (5176, 8431)\n",
      "1000 (5176, 8431)\n",
      "1500 (5176, 8431)\n",
      "2000 (5176, 8431)\n",
      "2500 (5176, 8431)\n",
      "3000 (5176, 8431)\n",
      "3500 (5176, 8431)\n",
      "4000 (5176, 8431)\n",
      "4500 (5176, 8431)\n",
      "5000 (5176, 8431)\n",
      "start\n",
      "iterating\n",
      "0 (805, 8431)\n",
      "500 (805, 8431)\n",
      "tp= 625 tn= 0 fp= 180 fn= 0\n",
      "scoring= 0.7763975155279503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    wb_x_train = apply_witten_bell(x_train[it])\n",
    "    wb_x_test = apply_witten_bell(x_test[it])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    clf.fit(wb_x_train, y_train[it])\n",
    "    predicted = clf.predict(wb_x_test)\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 5008 tn= 0 fp= 973 fn= 0\n",
      "scoring= 0.8373181742183581\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Turing Smoothing\n",
    "\n",
    "(without log-linear smoothing like Sampson, 1997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "iterating\n",
      "0 (5792, 9137)\n",
      "500 (5792, 9137)\n",
      "1000 (5792, 9137)\n",
      "1500 (5792, 9137)\n",
      "2000 (5792, 9137)\n",
      "2500 (5792, 9137)\n",
      "3000 (5792, 9137)\n",
      "3500 (5792, 9137)\n",
      "4000 (5792, 9137)\n",
      "4500 (5792, 9137)\n",
      "5000 (5792, 9137)\n",
      "5500 (5792, 9137)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9127</th>\n",
       "      <th>9128</th>\n",
       "      <th>9129</th>\n",
       "      <th>9130</th>\n",
       "      <th>9131</th>\n",
       "      <th>9132</th>\n",
       "      <th>9133</th>\n",
       "      <th>9134</th>\n",
       "      <th>9135</th>\n",
       "      <th>9136</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.004836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.020198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.004835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.014148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.013479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.006823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.013947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.025204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5762</th>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.013502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5770</th>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.002412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5771</th>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.006156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5772</th>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.006813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5776</th>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5782</th>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5783</th>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5784</th>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.012359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5785</th>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.007254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.012804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows × 9137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.001095  0.001095  0.001095  0.000000  0.001095  0.001095  0.001095   \n",
       "1     0.003071  0.003071  0.003071  0.000000  0.003071  0.003071  0.003071   \n",
       "2     0.004836  0.004836  0.004836  0.004836  0.004836  0.004836  0.004836   \n",
       "3     0.003950  0.003950  0.003950  0.000000  0.003950  0.003950  0.003950   \n",
       "4     0.001314  0.001314  0.001314  0.001314  0.001314  0.001314  0.001314   \n",
       "5     0.020198  0.020198  0.020198  0.020198  0.020198  0.527473  0.020198   \n",
       "6     0.003509  0.003509  0.003509  0.003509  0.003509  0.003509  0.003509   \n",
       "7     0.004831  0.004831  0.004831  0.000000  0.004831  0.004831  0.004831   \n",
       "8     0.001753  0.001753  0.001753  0.001753  0.001753  0.001753  0.001753   \n",
       "9     0.007706  0.007706  0.007706  2.857143  0.007706  0.007706  0.007706   \n",
       "10    0.001536  0.001536  0.001536  0.001536  0.001536  0.001536  0.001536   \n",
       "11    0.004835  0.004835  0.004835  0.004835  0.004835  0.004835  0.004835   \n",
       "12    0.002632  0.002632  0.002632  0.002632  0.002632  0.002632  0.002632   \n",
       "13    0.003511  0.003511  0.003511  0.003511  0.003511  0.750000  0.003511   \n",
       "14    0.000438  0.000438  0.000438  0.000000  0.000438  0.000438  0.000438   \n",
       "15    0.014148  0.014148  0.014148  0.014148  0.014148  0.014148  0.014148   \n",
       "16    0.000438  0.000438  0.000438  0.000438  0.000438  0.000438  0.000438   \n",
       "17    0.001315  0.001315  0.001315  0.001315  0.001315  0.001315  0.001315   \n",
       "18    0.013479  0.013479  0.013479  0.013479  0.013479  0.013479  0.013479   \n",
       "19    0.006823  0.006823  0.006823  0.006823  0.006823  0.006823  0.006823   \n",
       "20    0.002411  0.002411  0.002411  0.002411  0.002411  0.002411  0.002411   \n",
       "21    0.013947  0.013947  0.013947  0.013947  0.013947  0.013947  0.013947   \n",
       "22    0.004393  0.004393  0.004393  0.004393  2.000000  0.004393  0.004393   \n",
       "23    0.002412  0.002412  0.002412  0.002412  0.002412  0.002412  0.002412   \n",
       "24    0.003510  0.003510  0.003510  0.003510  0.003510  0.003510  0.003510   \n",
       "25    0.002631  0.002631  0.002631  0.002631  0.002631  0.002631  0.002631   \n",
       "26    0.025204  0.025204  0.025204  5.000000  1.333333  0.025204  0.025204   \n",
       "27    0.006381  0.006381  0.006381  1.000000  0.006381  0.006381  0.006381   \n",
       "28    0.000876  0.000876  0.000876  0.000000  0.000876  0.000876  0.000876   \n",
       "29    0.002631  0.002631  0.002631  0.750000  0.002631  0.002631  0.002631   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5762  0.013502  0.013502  0.013502  1.176471  0.013502  0.013502  0.013502   \n",
       "5763  0.002853  0.002853  0.002853  0.002853  0.002853  0.002853  0.002853   \n",
       "5764  0.002192  0.002192  0.002192  0.900000  0.002192  0.002192  0.002192   \n",
       "5765  0.001972  0.001972  0.001972  0.001972  0.001972  0.001972  0.001972   \n",
       "5766  0.002193  0.002193  0.002193  0.002193  0.002193  0.002193  0.002193   \n",
       "5767  0.001315  0.001315  0.001315  0.001315  0.001315  0.001315  0.001315   \n",
       "5768  0.004832  0.004832  0.004832  0.004832  0.004832  0.004832  0.004832   \n",
       "5769  0.004829  0.004829  0.004829  0.004829  0.004829  0.004829  0.004829   \n",
       "5770  0.002412  0.002412  0.002412  0.000000  0.002412  0.002412  0.002412   \n",
       "5771  0.006156  0.006156  0.006156  0.006156  0.006156  0.006156  0.006156   \n",
       "5772  0.004171  0.004171  0.004171  0.004171  0.004171  0.004171  0.004171   \n",
       "5773  0.006813  0.006813  0.006813  2.000000  0.006813  0.006813  0.006813   \n",
       "5774  0.006373  0.006373  0.006373  0.000000  0.006373  0.006373  0.006373   \n",
       "5775  0.003513  0.003513  0.003513  0.003513  0.003513  0.003513  0.003513   \n",
       "5776  0.003949  0.003949  0.003949  0.003949  0.003949  0.003949  0.003949   \n",
       "5777  0.002850  0.002850  0.002850  0.002850  0.002850  0.002850  0.002850   \n",
       "5778  0.000438  0.000438  0.000438  0.000000  0.000438  0.000438  0.000438   \n",
       "5779  0.004170  0.004170  0.004170  0.000000  0.004170  0.004170  0.004170   \n",
       "5780  0.002192  0.002192  0.002192  0.002192  0.002192  0.002192  0.002192   \n",
       "5781  0.001314  0.001314  0.001314  0.001314  0.001314  0.001314  0.001314   \n",
       "5782  0.004393  0.004393  0.004393  0.004393  0.004393  0.004393  0.004393   \n",
       "5783  0.001753  0.001753  0.001753  0.001753  0.001753  0.001753  0.001753   \n",
       "5784  0.012359  0.012359  0.012359  0.000000  0.012359  0.012359  0.012359   \n",
       "5785  0.019989  0.019989  0.019989  0.019989  0.019989  0.019989  0.019989   \n",
       "5786  0.004615  0.004615  0.004615  0.004615  0.004615  0.004615  0.004615   \n",
       "5787  0.006154  0.006154  0.006154  0.006154  0.006154  0.006154  0.006154   \n",
       "5788  0.001096  0.001096  0.001096  0.001096  0.001096  0.001096  0.001096   \n",
       "5789  0.000876  0.000876  0.000876  0.000000  0.000876  0.000876  0.000876   \n",
       "5790  0.007254  0.007254  0.007254  0.007254  0.007254  0.007254  0.007254   \n",
       "5791  0.012804  0.012804  0.012804  0.517241  2.800000  0.012804  0.012804   \n",
       "\n",
       "          7         8         9     ...      9127      9128      9129  \\\n",
       "0     0.001095  0.001095  0.001095  ...  0.001095  0.001095  0.001095   \n",
       "1     0.003071  0.003071  0.003071  ...  0.003071  0.003071  0.003071   \n",
       "2     0.004836  0.004836  0.004836  ...  0.004836  0.004836  0.004836   \n",
       "3     0.003950  0.003950  0.003950  ...  0.003950  0.003950  0.003950   \n",
       "4     0.001314  0.001314  0.001314  ...  0.001314  0.001314  0.001314   \n",
       "5     0.020198  0.020198  0.020198  ...  0.020198  0.020198  0.020198   \n",
       "6     0.003509  0.003509  0.003509  ...  0.003509  0.003509  0.003509   \n",
       "7     0.004831  0.004831  0.004831  ...  0.004831  0.004831  0.004831   \n",
       "8     0.001753  0.001753  0.001753  ...  0.001753  0.001753  0.001753   \n",
       "9     0.007706  0.007706  0.007706  ...  0.007706  0.007706  0.007706   \n",
       "10    0.001536  0.001536  0.001536  ...  0.001536  0.001536  0.001536   \n",
       "11    0.004835  0.004835  0.004835  ...  0.004835  0.004835  0.004835   \n",
       "12    0.002632  0.002632  0.002632  ...  0.002632  0.002632  0.002632   \n",
       "13    0.003511  0.003511  0.003511  ...  0.003511  0.003511  0.003511   \n",
       "14    0.000438  0.000438  0.000438  ...  0.000438  0.000438  0.000438   \n",
       "15    0.014148  0.014148  0.014148  ...  0.014148  0.014148  0.014148   \n",
       "16    0.000438  0.000438  0.000438  ...  0.000438  0.000438  0.000438   \n",
       "17    0.001315  0.001315  0.001315  ...  0.001315  0.001315  0.001315   \n",
       "18    0.013479  0.013479  0.013479  ...  0.013479  0.013479  0.013479   \n",
       "19    0.006823  0.006823  0.006823  ...  0.006823  0.006823  0.006823   \n",
       "20    0.002411  0.002411  0.002411  ...  0.002411  0.002411  0.002411   \n",
       "21    0.013947  0.013947  0.013947  ...  0.013947  0.013947  0.013947   \n",
       "22    2.000000  0.004393  0.004393  ...  0.004393  0.004393  0.004393   \n",
       "23    0.002412  0.002412  0.002412  ...  0.002412  0.002412  0.002412   \n",
       "24    0.003510  0.003510  0.003510  ...  0.003510  0.003510  0.003510   \n",
       "25    0.002631  0.002631  0.002631  ...  0.002631  0.002631  0.002631   \n",
       "26    1.333333  0.025204  0.025204  ...  0.025204  0.025204  0.025204   \n",
       "27    0.006381  0.006381  0.006381  ...  0.006381  0.006381  0.006381   \n",
       "28    0.000876  0.000876  0.000876  ...  0.000876  0.000876  0.000876   \n",
       "29    0.002631  0.002631  0.002631  ...  0.002631  0.002631  0.002631   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5762  0.013502  0.013502  0.013502  ...  0.013502  0.013502  0.013502   \n",
       "5763  0.002853  0.002853  0.002853  ...  0.002853  0.002853  0.002853   \n",
       "5764  0.002192  0.002192  0.002192  ...  0.002192  0.002192  0.002192   \n",
       "5765  0.001972  0.001972  0.001972  ...  0.001972  0.001972  0.001972   \n",
       "5766  0.002193  0.002193  0.002193  ...  0.002193  0.002193  0.002193   \n",
       "5767  0.001315  0.001315  0.001315  ...  0.001315  0.001315  0.001315   \n",
       "5768  0.004832  0.004832  0.004832  ...  0.004832  0.004832  0.004832   \n",
       "5769  0.004829  0.004829  0.004829  ...  0.004829  0.004829  0.004829   \n",
       "5770  0.002412  0.002412  0.002412  ...  0.002412  0.002412  0.002412   \n",
       "5771  0.006156  0.006156  0.006156  ...  0.006156  0.006156  0.006156   \n",
       "5772  0.004171  0.004171  0.004171  ...  0.004171  0.004171  0.004171   \n",
       "5773  0.006813  0.006813  0.006813  ...  0.006813  0.006813  0.006813   \n",
       "5774  0.006373  0.006373  0.006373  ...  0.006373  0.006373  0.006373   \n",
       "5775  0.003513  0.003513  0.003513  ...  0.003513  0.003513  0.003513   \n",
       "5776  0.003949  0.003949  0.003949  ...  0.003949  0.003949  0.003949   \n",
       "5777  0.002850  0.002850  0.002850  ...  0.002850  0.002850  0.002850   \n",
       "5778  0.000438  0.000438  0.000438  ...  0.000438  0.000438  0.000438   \n",
       "5779  0.004170  0.004170  0.004170  ...  0.004170  0.004170  0.004170   \n",
       "5780  0.002192  0.002192  0.002192  ...  0.002192  0.002192  0.002192   \n",
       "5781  0.001314  0.001314  0.001314  ...  0.001314  0.001314  0.001314   \n",
       "5782  0.004393  0.004393  0.004393  ...  0.004393  0.004393  0.004393   \n",
       "5783  0.001753  0.001753  0.001753  ...  0.001753  0.001753  0.001753   \n",
       "5784  0.012359  0.012359  0.012359  ...  0.012359  0.012359  0.012359   \n",
       "5785  0.019989  0.019989  0.019989  ...  0.019989  0.019989  0.019989   \n",
       "5786  0.004615  0.004615  0.004615  ...  0.004615  0.004615  0.004615   \n",
       "5787  0.006154  0.006154  0.006154  ...  0.006154  0.006154  0.006154   \n",
       "5788  0.001096  0.001096  0.001096  ...  0.001096  0.001096  0.001096   \n",
       "5789  0.000876  0.000876  0.000876  ...  0.000876  0.000876  0.000876   \n",
       "5790  0.007254  0.007254  0.007254  ...  0.007254  0.007254  0.007254   \n",
       "5791  2.800000  0.012804  0.012804  ...  0.012804  0.012804  0.012804   \n",
       "\n",
       "          9130      9131      9132      9133      9134      9135      9136  \n",
       "0     0.001095  0.001095  0.001095  0.001095  0.001095  0.001095  0.001095  \n",
       "1     0.003071  0.003071  0.003071  0.003071  0.003071  0.003071  0.003071  \n",
       "2     0.004836  0.004836  0.004836  0.004836  0.004836  0.004836  0.004836  \n",
       "3     0.003950  0.003950  0.003950  0.003950  0.003950  0.003950  0.003950  \n",
       "4     0.001314  0.001314  0.001314  0.001314  0.001314  0.001314  0.001314  \n",
       "5     0.020198  0.020198  0.020198  0.020198  0.020198  0.020198  0.020198  \n",
       "6     0.003509  0.003509  0.003509  0.003509  0.003509  0.003509  0.003509  \n",
       "7     0.004831  0.004831  0.004831  0.004831  0.004831  0.004831  0.004831  \n",
       "8     0.001753  0.001753  0.001753  0.001753  0.001753  0.001753  0.001753  \n",
       "9     0.007706  0.007706  0.007706  0.007706  0.007706  0.007706  0.007706  \n",
       "10    0.001536  0.001536  0.001536  0.001536  0.001536  0.001536  0.001536  \n",
       "11    0.004835  0.004835  0.004835  0.004835  0.004835  0.004835  0.004835  \n",
       "12    0.002632  0.002632  0.002632  0.002632  0.002632  0.002632  0.002632  \n",
       "13    0.003511  0.003511  0.003511  0.003511  0.003511  0.003511  0.003511  \n",
       "14    0.000438  0.000438  0.000438  0.000438  0.000438  0.000438  0.000438  \n",
       "15    0.014148  0.014148  0.014148  0.014148  0.014148  0.014148  0.014148  \n",
       "16    0.000438  0.000438  0.000438  0.000438  0.000438  0.000438  0.000438  \n",
       "17    0.001315  0.001315  0.001315  0.001315  0.001315  0.001315  0.001315  \n",
       "18    0.013479  0.013479  0.013479  0.013479  0.013479  0.013479  0.013479  \n",
       "19    0.006823  0.006823  0.006823  0.006823  0.006823  0.006823  0.006823  \n",
       "20    0.002411  0.002411  0.002411  0.002411  0.002411  0.002411  0.002411  \n",
       "21    0.013947  0.013947  0.013947  0.013947  0.013947  0.013947  0.013947  \n",
       "22    0.004393  0.004393  0.004393  0.004393  0.004393  0.004393  0.004393  \n",
       "23    0.002412  0.002412  0.002412  0.002412  0.002412  0.002412  0.002412  \n",
       "24    0.003510  0.003510  0.003510  0.003510  0.003510  0.003510  0.003510  \n",
       "25    0.002631  0.002631  0.002631  0.002631  0.002631  0.002631  0.002631  \n",
       "26    0.025204  0.025204  0.025204  0.025204  0.025204  0.025204  0.025204  \n",
       "27    0.006381  0.006381  0.006381  0.006381  0.006381  0.006381  0.006381  \n",
       "28    0.000876  0.000876  0.000876  0.000876  0.000876  0.000876  0.000876  \n",
       "29    0.002631  0.002631  0.002631  0.002631  0.002631  0.002631  0.002631  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5762  0.013502  0.013502  0.013502  0.013502  0.013502  0.013502  0.013502  \n",
       "5763  0.002853  0.002853  0.002853  0.002853  0.002853  0.002853  0.002853  \n",
       "5764  0.002192  0.002192  0.002192  0.002192  0.002192  0.002192  0.002192  \n",
       "5765  0.001972  0.001972  0.001972  0.001972  0.001972  0.001972  0.001972  \n",
       "5766  0.002193  0.002193  0.002193  0.002193  0.002193  0.002193  0.002193  \n",
       "5767  0.001315  0.001315  0.001315  0.001315  0.001315  0.001315  0.001315  \n",
       "5768  0.004832  0.004832  0.004832  0.004832  0.004832  0.004832  0.004832  \n",
       "5769  0.004829  0.004829  0.004829  0.004829  0.004829  0.004829  0.004829  \n",
       "5770  0.002412  0.002412  0.002412  0.002412  0.002412  0.002412  0.002412  \n",
       "5771  0.006156  0.006156  0.006156  0.006156  0.006156  0.006156  0.006156  \n",
       "5772  0.004171  0.004171  0.004171  0.004171  0.004171  0.004171  0.004171  \n",
       "5773  0.006813  0.006813  0.006813  0.006813  0.006813  0.006813  0.006813  \n",
       "5774  0.006373  0.006373  0.006373  0.006373  0.006373  0.006373  0.006373  \n",
       "5775  0.003513  0.003513  0.003513  0.003513  0.003513  0.003513  0.003513  \n",
       "5776  0.003949  0.003949  0.003949  0.003949  0.003949  0.003949  0.003949  \n",
       "5777  0.002850  0.002850  0.002850  0.002850  0.002850  0.002850  0.002850  \n",
       "5778  0.000438  0.000438  0.000438  0.000438  0.000438  0.000438  0.000438  \n",
       "5779  0.004170  0.004170  0.473684  0.004170  0.004170  0.004170  0.004170  \n",
       "5780  0.002192  0.002192  0.002192  0.002192  0.002192  0.002192  0.002192  \n",
       "5781  0.001314  0.001314  0.001314  0.001314  0.001314  0.001314  0.001314  \n",
       "5782  0.004393  0.004393  0.004393  0.004393  0.004393  0.004393  0.004393  \n",
       "5783  0.001753  0.001753  0.001753  0.001753  0.001753  0.001753  0.001753  \n",
       "5784  0.012359  0.012359  0.012359  0.012359  0.012359  0.012359  0.012359  \n",
       "5785  0.019989  0.019989  0.019989  0.019989  0.019989  0.019989  0.019989  \n",
       "5786  0.004615  0.004615  0.004615  0.004615  0.004615  0.004615  0.004615  \n",
       "5787  0.006154  0.006154  0.006154  0.006154  0.006154  0.006154  0.006154  \n",
       "5788  0.001096  0.001096  0.001096  0.001096  0.001096  0.001096  0.001096  \n",
       "5789  0.000876  0.000876  0.000876  0.000876  0.000876  0.000876  0.000876  \n",
       "5790  0.007254  0.007254  0.007254  0.007254  0.007254  0.007254  0.007254  \n",
       "5791  0.012804  0.012804  0.012804  0.012804  0.012804  0.012804  0.012804  \n",
       "\n",
       "[5792 rows x 9137 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_good_turing(x):\n",
    "    print(\"start\")\n",
    "    df_x = pd.DataFrame(x)\n",
    "    \n",
    "    df_x = df_x + 1 #add one as mentioned in paper\n",
    "    \n",
    "    print(\"iterating\")\n",
    "    res = []\n",
    "\n",
    "    for it, row in df_x.iterrows():\n",
    "        r_stars = {}\n",
    "        if it %500 == 0:\n",
    "            print(it, df_x.shape)\n",
    "            \n",
    "        vc = row.value_counts().to_dict()\n",
    "        for it in range(0, max(vc.keys())):\n",
    "            if it not in vc:\n",
    "                vc[it]= 0\n",
    "        #print(vc)\n",
    "        \n",
    "        for r in sorted(vc):\n",
    "            Nr_plus_1 = 0 if r+1 not in vc else vc[r+1]\n",
    "            Nr = vc[r] if r in vc else [vc[r_] for r_ in range(r, 0) if vc[r_1] > 0][0] # take next smallest value\n",
    "            Nr = Nr if Nr > 0 else 1\n",
    "            r_star = (r + 1) * (Nr_plus_1/Nr)\n",
    "            #print(\"r*\", r, Nr, Nr_plus_1, (Nr_plus_1/Nr) , r_star)\n",
    "            r_stars[r] = r_star\n",
    "        #print(vc, r_stars)\n",
    "        for it in range(0, max(r_stars.keys())):\n",
    "            if it not in r_stars:\n",
    "                r_stars[it]= 0\n",
    "        #print(vc)\n",
    "        \n",
    "        res.append(row.map(lambda n: r_stars[n]))\n",
    "      \n",
    "    df_res = pd.DataFrame(res)\n",
    "\n",
    "    return df_res\n",
    "\n",
    "text = [[1,0,1,0,1], [2,1,0,1,2], [5,0,0,1,0], [2,3,0,0,0]]\n",
    "apply_good_turing(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "iterating\n",
      "0 (5792, 9137)\n",
      "500 (5792, 9137)\n",
      "1000 (5792, 9137)\n",
      "1500 (5792, 9137)\n",
      "2000 (5792, 9137)\n",
      "2500 (5792, 9137)\n",
      "3000 (5792, 9137)\n",
      "3500 (5792, 9137)\n",
      "4000 (5792, 9137)\n",
      "4500 (5792, 9137)\n",
      "5000 (5792, 9137)\n",
      "5500 (5792, 9137)\n",
      "start\n",
      "iterating\n",
      "0 (189, 9137)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 137 tn= 17 fp= 16 fn= 19\n",
      "scoring= 0.8148148148148148\n",
      "start\n",
      "iterating\n",
      "0 (4591, 7935)\n",
      "500 (4591, 7935)\n",
      "1000 (4591, 7935)\n",
      "1500 (4591, 7935)\n",
      "2000 (4591, 7935)\n",
      "2500 (4591, 7935)\n",
      "3000 (4591, 7935)\n",
      "3500 (4591, 7935)\n",
      "4000 (4591, 7935)\n",
      "4500 (4591, 7935)\n",
      "start\n",
      "iterating\n",
      "0 (1390, 7935)\n",
      "500 (1390, 7935)\n",
      "1000 (1390, 7935)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 1110 tn= 90 fp= 119 fn= 71\n",
      "scoring= 0.8633093525179856\n",
      "start\n",
      "iterating\n",
      "0 (4960, 8068)\n",
      "500 (4960, 8068)\n",
      "1000 (4960, 8068)\n",
      "1500 (4960, 8068)\n",
      "2000 (4960, 8068)\n",
      "2500 (4960, 8068)\n",
      "3000 (4960, 8068)\n",
      "3500 (4960, 8068)\n",
      "4000 (4960, 8068)\n",
      "4500 (4960, 8068)\n",
      "start\n",
      "iterating\n",
      "0 (1021, 8068)\n",
      "500 (1021, 8068)\n",
      "1000 (1021, 8068)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 774 tn= 80 fp= 107 fn= 60\n",
      "scoring= 0.8364348677766895\n",
      "start\n",
      "iterating\n",
      "0 (4320, 7986)\n",
      "500 (4320, 7986)\n",
      "1000 (4320, 7986)\n",
      "1500 (4320, 7986)\n",
      "2000 (4320, 7986)\n",
      "2500 (4320, 7986)\n",
      "3000 (4320, 7986)\n",
      "3500 (4320, 7986)\n",
      "4000 (4320, 7986)\n",
      "start\n",
      "iterating\n",
      "0 (1661, 7986)\n",
      "500 (1661, 7986)\n",
      "1000 (1661, 7986)\n",
      "1500 (1661, 7986)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 1299 tn= 101 fp= 125 fn= 136\n",
      "scoring= 0.8428657435279951\n",
      "start\n",
      "iterating\n",
      "0 (5283, 8299)\n",
      "500 (5283, 8299)\n",
      "1000 (5283, 8299)\n",
      "1500 (5283, 8299)\n",
      "2000 (5283, 8299)\n",
      "2500 (5283, 8299)\n",
      "3000 (5283, 8299)\n",
      "3500 (5283, 8299)\n",
      "4000 (5283, 8299)\n",
      "4500 (5283, 8299)\n",
      "5000 (5283, 8299)\n",
      "start\n",
      "iterating\n",
      "0 (698, 8299)\n",
      "500 (698, 8299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 509 tn= 52 fp= 67 fn= 70\n",
      "scoring= 0.8037249283667621\n",
      "start\n",
      "iterating\n",
      "0 (5764, 8823)\n",
      "500 (5764, 8823)\n",
      "1000 (5764, 8823)\n",
      "1500 (5764, 8823)\n",
      "2000 (5764, 8823)\n",
      "2500 (5764, 8823)\n",
      "3000 (5764, 8823)\n",
      "3500 (5764, 8823)\n",
      "4000 (5764, 8823)\n",
      "4500 (5764, 8823)\n",
      "5000 (5764, 8823)\n",
      "5500 (5764, 8823)\n",
      "start\n",
      "iterating\n",
      "0 (217, 8823)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 181 tn= 9 fp= 10 fn= 17\n",
      "scoring= 0.8755760368663594\n",
      "start\n",
      "iterating\n",
      "0 (5176, 8431)\n",
      "500 (5176, 8431)\n",
      "1000 (5176, 8431)\n",
      "1500 (5176, 8431)\n",
      "2000 (5176, 8431)\n",
      "2500 (5176, 8431)\n",
      "3000 (5176, 8431)\n",
      "3500 (5176, 8431)\n",
      "4000 (5176, 8431)\n",
      "4500 (5176, 8431)\n",
      "5000 (5176, 8431)\n",
      "start\n",
      "iterating\n",
      "0 (805, 8431)\n",
      "500 (805, 8431)\n",
      "tp= 559 tn= 74 fp= 106 fn= 66\n",
      "scoring= 0.7863354037267081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    gt_x_train = apply_good_turing(x_train[it])\n",
    "    gt_x_test = apply_good_turing(x_test[it])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    clf.fit(gt_x_train, y_train[it])\n",
    "    predicted = clf.predict(gt_x_test)\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 4569 tn= 423 fp= 550 fn= 439\n",
      "scoring= 0.8346430362815582\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_grams(tokens, n):\n",
    "    res = []\n",
    "    for it in range(0, len(tokens) -(n-1)):\n",
    "        res.append(\" \". join(tokens[it: it +n]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "5792 189 5792 189\n",
      "4591 1390 4591 1390\n",
      "4960 1021 4960 1021\n",
      "4320 1661 4320 1661\n",
      "5283 698 5283 698\n",
      "5764 217 5764 217\n",
      "5176 805 5176 805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "datasets = load_dataset(dataset_paths[0])\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=literal_eval)\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_train = dataset[0]\n",
    "    df_test = dataset[1]\n",
    "    df_train[\"tokens\"] = df_train.tokens.map(lambda tokens: str(create_n_grams(literal_eval(tokens), 2)))\n",
    "    df_test[\"tokens\"] = df_test.tokens.map(lambda tokens: str(create_n_grams(literal_eval(tokens), 2)))\n",
    "    \n",
    "    temp_train = vectorizer.fit_transform(df_train[\"tokens\"])\n",
    "    x_train.append(temp_train.toarray())\n",
    "    y_train.append(df_train.bool_rating.tolist())\n",
    "\n",
    "    temp_test = vectorizer.transform(df_test[\"tokens\"])\n",
    "    x_test.append(temp_test.toarray())\n",
    "    y_test.append(df_test.bool_rating.tolist())\n",
    "\n",
    "    print(len(x_train[-1]), len(x_test[-1]), len(y_train[-1]), len(y_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 148 tn= 25 fp= 8 fn= 8\n",
      "scoring= 0.9153439153439153\n",
      "tp= 1137 tn= 142 fp= 67 fn= 44\n",
      "scoring= 0.9201438848920863\n",
      "tp= 812 tn= 107 fp= 80 fn= 22\n",
      "scoring= 0.9000979431929481\n",
      "tp= 1419 tn= 128 fp= 98 fn= 16\n",
      "scoring= 0.9313666465984347\n",
      "tp= 566 tn= 82 fp= 37 fn= 13\n",
      "scoring= 0.9283667621776505\n",
      "tp= 191 tn= 13 fp= 6 fn= 7\n",
      "scoring= 0.9400921658986175\n",
      "tp= 622 tn= 106 fp= 74 fn= 3\n",
      "scoring= 0.9043478260869565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    clf.fit(x_train[it], y_train[it])\n",
    "    predicted = clf.predict(x_test[it])\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 4895 tn= 603 fp= 370 fn= 113\n",
      "scoring= 0.919244273532854\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(dataset_paths[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=literal_eval)\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_train = dataset[0]\n",
    "    df_test = dataset[1]\n",
    "    \n",
    "    temp_train = vectorizer.fit_transform(df_train[\"tokens\"])\n",
    "    x_train.append(temp_train.toarray())\n",
    "    y_train.append(df_train.bool_rating.tolist())\n",
    "\n",
    "    temp_test = vectorizer.transform(df_test[\"tokens\"])\n",
    "    x_test.append(temp_test.toarray())\n",
    "    y_test.append(df_test.bool_rating.tolist())\n",
    "\n",
    "    print(len(x_train[-1]), len(x_test[-1]), len(y_train[-1]), len(y_test[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 208 tn= 218 fp= 6 fn= 16\n",
      "scoring= 0.9508928571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 221 tn= 221 fp= 3 fn= 3\n",
      "scoring= 0.9866071428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 217 tn= 213 fp= 11 fn= 7\n",
      "scoring= 0.9598214285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 216 tn= 217 fp= 7 fn= 8\n",
      "scoring= 0.9665178571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 213 tn= 218 fp= 6 fn= 11\n",
      "scoring= 0.9620535714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 212 tn= 213 fp= 11 fn= 12\n",
      "scoring= 0.9486607142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 214 tn= 214 fp= 10 fn= 10\n",
      "scoring= 0.9553571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 214 tn= 216 fp= 8 fn= 10\n",
      "scoring= 0.9598214285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 217 tn= 218 fp= 6 fn= 7\n",
      "scoring= 0.9709821428571429\n",
      "tp= 213 tn= 214 fp= 10 fn= 11\n",
      "scoring= 0.953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    clf.fit(x_train[it], y_train[it])\n",
    "    predicted = clf.predict(x_test[it])\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 2145 tn= 2162 fp= 78 fn= 95\n",
      "scoring= 0.9613839285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 202 tn= 217 fp= 7 fn= 22\n",
      "scoring= 0.9352678571428571\n",
      "tp= 211 tn= 218 fp= 6 fn= 13\n",
      "scoring= 0.9575892857142857\n",
      "tp= 214 tn= 215 fp= 9 fn= 10\n",
      "scoring= 0.9575892857142857\n",
      "tp= 210 tn= 219 fp= 5 fn= 14\n",
      "scoring= 0.9575892857142857\n",
      "tp= 214 tn= 218 fp= 6 fn= 10\n",
      "scoring= 0.9642857142857143\n",
      "tp= 210 tn= 211 fp= 13 fn= 14\n",
      "scoring= 0.9397321428571429\n",
      "tp= 203 tn= 212 fp= 12 fn= 21\n",
      "scoring= 0.9263392857142857\n",
      "tp= 210 tn= 219 fp= 5 fn= 14\n",
      "scoring= 0.9575892857142857\n",
      "tp= 212 tn= 221 fp= 3 fn= 12\n",
      "scoring= 0.9665178571428571\n",
      "tp= 209 tn= 212 fp= 12 fn= 15\n",
      "scoring= 0.9397321428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    clf.fit(x_train[it], y_train[it])\n",
    "    predicted = clf.predict(x_test[it])\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 2095 tn= 2162 fp= 78 fn= 145\n",
      "scoring= 0.9502232142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Witten Bell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_witten_bell(x):\n",
    "    print(\"start\")\n",
    "    df_x = pd.DataFrame(x)\n",
    "    print(\"iterating\")\n",
    "    res = []\n",
    "\n",
    "    for it, row in df_x.iterrows():\n",
    "        \n",
    "        if it %500 == 0:\n",
    "            print(it, x.shape)\n",
    "        N = sum(row)\n",
    "        #print(\"N\", N)\n",
    "        M = sum([1 for x in row if x != 0])\n",
    "        #print(\"M\", M)\n",
    "        row = row/row.sum()\n",
    "        nval = 1/(N+M)\n",
    "        #print(\"applying\", nval)\n",
    "        row = row.replace(0, nval)\n",
    "        #print(\"set value\")\n",
    "        res.append(row)\n",
    "        #print(\"ready with row\")\n",
    "    df_res = pd.DataFrame(res)\n",
    "\n",
    "    return df_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "iterating\n",
      "0 (4032, 7418)\n",
      "500 (4032, 7418)\n",
      "1000 (4032, 7418)\n",
      "1500 (4032, 7418)\n",
      "2000 (4032, 7418)\n",
      "2500 (4032, 7418)\n",
      "3000 (4032, 7418)\n",
      "3500 (4032, 7418)\n",
      "4000 (4032, 7418)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 160 tn= 189 fp= 35 fn= 64\n",
      "scoring= 0.7790178571428571\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7408)\n",
      "500 (4032, 7408)\n",
      "1000 (4032, 7408)\n",
      "1500 (4032, 7408)\n",
      "2000 (4032, 7408)\n",
      "2500 (4032, 7408)\n",
      "3000 (4032, 7408)\n",
      "3500 (4032, 7408)\n",
      "4000 (4032, 7408)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7408)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 168 tn= 189 fp= 35 fn= 56\n",
      "scoring= 0.796875\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7376)\n",
      "500 (4032, 7376)\n",
      "1000 (4032, 7376)\n",
      "1500 (4032, 7376)\n",
      "2000 (4032, 7376)\n",
      "2500 (4032, 7376)\n",
      "3000 (4032, 7376)\n",
      "3500 (4032, 7376)\n",
      "4000 (4032, 7376)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 165 tn= 192 fp= 32 fn= 59\n",
      "scoring= 0.796875\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7410)\n",
      "500 (4032, 7410)\n",
      "1000 (4032, 7410)\n",
      "1500 (4032, 7410)\n",
      "2000 (4032, 7410)\n",
      "2500 (4032, 7410)\n",
      "3000 (4032, 7410)\n",
      "3500 (4032, 7410)\n",
      "4000 (4032, 7410)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7410)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 161 tn= 188 fp= 36 fn= 63\n",
      "scoring= 0.7790178571428571\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7436)\n",
      "500 (4032, 7436)\n",
      "1000 (4032, 7436)\n",
      "1500 (4032, 7436)\n",
      "2000 (4032, 7436)\n",
      "2500 (4032, 7436)\n",
      "3000 (4032, 7436)\n",
      "3500 (4032, 7436)\n",
      "4000 (4032, 7436)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7436)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 159 tn= 199 fp= 25 fn= 65\n",
      "scoring= 0.7991071428571429\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7366)\n",
      "500 (4032, 7366)\n",
      "1000 (4032, 7366)\n",
      "1500 (4032, 7366)\n",
      "2000 (4032, 7366)\n",
      "2500 (4032, 7366)\n",
      "3000 (4032, 7366)\n",
      "3500 (4032, 7366)\n",
      "4000 (4032, 7366)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7366)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 155 tn= 189 fp= 35 fn= 69\n",
      "scoring= 0.7678571428571429\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7458)\n",
      "500 (4032, 7458)\n",
      "1000 (4032, 7458)\n",
      "1500 (4032, 7458)\n",
      "2000 (4032, 7458)\n",
      "2500 (4032, 7458)\n",
      "3000 (4032, 7458)\n",
      "3500 (4032, 7458)\n",
      "4000 (4032, 7458)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7458)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 154 tn= 195 fp= 29 fn= 70\n",
      "scoring= 0.7790178571428571\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7191)\n",
      "500 (4032, 7191)\n",
      "1000 (4032, 7191)\n",
      "1500 (4032, 7191)\n",
      "2000 (4032, 7191)\n",
      "2500 (4032, 7191)\n",
      "3000 (4032, 7191)\n",
      "3500 (4032, 7191)\n",
      "4000 (4032, 7191)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7191)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 154 tn= 191 fp= 33 fn= 70\n",
      "scoring= 0.7700892857142857\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7414)\n",
      "500 (4032, 7414)\n",
      "1000 (4032, 7414)\n",
      "1500 (4032, 7414)\n",
      "2000 (4032, 7414)\n",
      "2500 (4032, 7414)\n",
      "3000 (4032, 7414)\n",
      "3500 (4032, 7414)\n",
      "4000 (4032, 7414)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7414)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 160 tn= 187 fp= 37 fn= 64\n",
      "scoring= 0.7745535714285714\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7356)\n",
      "500 (4032, 7356)\n",
      "1000 (4032, 7356)\n",
      "1500 (4032, 7356)\n",
      "2000 (4032, 7356)\n",
      "2500 (4032, 7356)\n",
      "3000 (4032, 7356)\n",
      "3500 (4032, 7356)\n",
      "4000 (4032, 7356)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7356)\n",
      "tp= 161 tn= 193 fp= 31 fn= 63\n",
      "scoring= 0.7901785714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    wb_x_train = apply_witten_bell(x_train[it])\n",
    "    wb_x_test = apply_witten_bell(x_test[it])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    clf.fit(wb_x_train, y_train[it])\n",
    "    predicted = clf.predict(wb_x_test)\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 1597 tn= 1912 fp= 328 fn= 643\n",
      "scoring= 0.7832589285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Turing Smoothing\n",
    "\n",
    "(without log-linear smoothing like Sampson, 1997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "iterating\n",
      "0 (4032, 7418)\n",
      "500 (4032, 7418)\n",
      "1000 (4032, 7418)\n",
      "1500 (4032, 7418)\n",
      "2000 (4032, 7418)\n",
      "2500 (4032, 7418)\n",
      "3000 (4032, 7418)\n",
      "3500 (4032, 7418)\n",
      "4000 (4032, 7418)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7408</th>\n",
       "      <th>7409</th>\n",
       "      <th>7410</th>\n",
       "      <th>7411</th>\n",
       "      <th>7412</th>\n",
       "      <th>7413</th>\n",
       "      <th>7414</th>\n",
       "      <th>7415</th>\n",
       "      <th>7416</th>\n",
       "      <th>7417</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.015269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.011675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.004055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.004054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.017173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.007321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.003513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.002975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.014436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.002162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.019970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.002705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.028005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.005686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.015259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.006228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.008954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.004875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.008136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.014426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.014194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.027179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.022484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4032 rows × 7418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3          4         5         6     \\\n",
       "0     0.005139  0.005139  0.005139  0.005139   0.005139  0.005139  0.005139   \n",
       "1     0.002160  0.002160  0.002160  0.750000   0.002160  0.002160  0.002160   \n",
       "2     0.003785  0.003785  0.003785  0.003785   0.003785  0.003785  0.003785   \n",
       "3     0.003785  0.003785  0.003785  0.000000   0.003785  0.003785  0.003785   \n",
       "4     0.005960  0.005960  0.005960  0.005960   0.005960  0.005960  0.005960   \n",
       "5     0.000810  0.000810  0.000810  1.000000   0.000810  0.000810  0.000810   \n",
       "6     0.002430  0.002430  0.002430  0.666667   0.002430  0.002430  0.002430   \n",
       "7     0.004060  0.004060  0.004060  0.004060   0.004060  0.004060  0.004060   \n",
       "8     0.001079  0.001079  0.001079  0.001079   0.001079  0.001079  0.001079   \n",
       "9     0.001890  0.001890  0.001890  0.001890   0.001890  0.001890  0.001890   \n",
       "10    0.015269  0.015269  0.015269  0.015269   0.015269  0.015269  0.015269   \n",
       "11    0.011675  0.011675  0.011675  0.011675   0.558140  0.011675  0.011675   \n",
       "12    0.004055  0.004055  0.004055  0.004055   0.004055  0.004055  0.004055   \n",
       "13    0.004055  0.004055  0.004055  0.000000   0.004055  0.004055  0.004055   \n",
       "14    0.002972  0.002972  0.002972  0.000000   0.002972  0.002972  0.002972   \n",
       "15    0.001892  0.001892  0.001892  0.555556   0.001892  0.001892  0.001892   \n",
       "16    0.004054  0.004054  0.004054  0.004054   0.004054  0.004054  0.004054   \n",
       "17    0.017173  0.017173  0.017173  0.428571   0.017173  0.017173  0.017173   \n",
       "18    0.003241  0.003241  0.003241  0.003241   0.003241  0.003241  0.003241   \n",
       "19    0.004869  0.004869  0.004869  0.004869   0.004869  0.004869  0.004869   \n",
       "20    0.007321  0.007321  0.007321  2.000000   0.007321  0.007321  0.007321   \n",
       "21    0.002704  0.002704  0.002704  0.002704   0.002704  0.002704  0.002704   \n",
       "22    0.003513  0.003513  0.003513  0.003513   0.003513  0.003513  0.003513   \n",
       "23    0.002975  0.002975  0.002975  0.002975   0.002975  0.002975  0.002975   \n",
       "24    0.014436  0.014436  0.014436  0.000000   0.014436  0.014436  0.014436   \n",
       "25    0.006770  0.006770  0.006770  0.480000   0.006770  0.006770  0.006770   \n",
       "26    0.002160  0.002160  0.002160  0.002160   0.002160  0.002160  0.002160   \n",
       "27    0.003514  0.003514  0.003514  0.003514   0.003514  0.003514  0.003514   \n",
       "28    0.002162  0.002162  0.002162  0.002162   1.142857  0.002162  0.002162   \n",
       "29    0.004060  0.004060  0.004060  0.004060   0.004060  0.004060  0.004060   \n",
       "...        ...       ...       ...       ...        ...       ...       ...   \n",
       "4002  0.003246  0.003246  0.003246  0.003246   0.003246  0.003246  0.003246   \n",
       "4003  0.002701  0.002701  0.002701  0.002701   0.002701  0.002701  0.002701   \n",
       "4004  0.001350  0.001350  0.001350  0.000000   0.001350  0.001350  0.001350   \n",
       "4005  0.004596  0.004596  0.004596  0.004596   0.004596  0.004596  0.004596   \n",
       "4006  0.002701  0.002701  0.002701  0.002701   0.002701  0.002701  0.002701   \n",
       "4007  0.003784  0.003784  0.003784  0.003784   0.003784  0.003784  0.003784   \n",
       "4008  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "4009  0.008955  0.008955  0.008955  3.333333   0.008955  0.008955  0.008955   \n",
       "4010  0.019970  0.019970  0.019970  0.019970  12.000000  0.019970  0.019970   \n",
       "4011  0.002705  0.002705  0.002705  0.002705   0.002705  0.002705  0.002705   \n",
       "4012  0.028005  0.028005  0.028005  0.028005   0.028005  0.028005  0.028005   \n",
       "4013  0.004603  0.004603  0.004603  0.000000   0.004603  0.004603  0.004603   \n",
       "4014  0.005686  0.005686  0.005686  0.005686   0.005686  0.005686  0.005686   \n",
       "4015  0.015259  0.015259  0.015259  2.000000   0.015259  0.015259  0.015259   \n",
       "4016  0.002701  0.002701  0.002701  0.000000   0.002701  0.002701  0.002701   \n",
       "4017  0.012794  0.012794  0.012794  0.765957   0.012794  0.012794  0.012794   \n",
       "4018  0.001890  0.001890  0.001890  0.001890   0.001890  0.001890  0.001890   \n",
       "4019  0.006228  0.006228  0.006228  0.006228   0.006228  0.006228  0.006228   \n",
       "4020  0.008954  0.008954  0.008954  3.000000   0.008954  0.008954  0.008954   \n",
       "4021  0.004875  0.004875  0.004875  0.004875   0.004875  0.004875  0.004875   \n",
       "4022  0.008136  0.008136  0.008136  0.008136   0.008136  0.008136  0.008136   \n",
       "4023  0.004325  0.004325  0.004325  0.004325   0.004325  0.004325  0.004325   \n",
       "4024  0.014426  0.014426  0.014426  0.014426   0.615385  0.014426  0.014426   \n",
       "4025  0.003515  0.003515  0.003515  0.003515   0.003515  0.003515  0.003515   \n",
       "4026  0.014194  0.014194  0.014194  0.980769   0.014194  0.014194  0.014194   \n",
       "4027  0.027179  0.027179  0.027179  0.027179   0.484848  0.027179  0.027179   \n",
       "4028  0.004601  0.004601  0.004601  0.004601   0.004601  0.004601  0.004601   \n",
       "4029  0.004872  0.004872  0.004872  0.004872   0.004872  0.004872  0.004872   \n",
       "4030  0.003242  0.003242  0.003242  0.003242   0.003242  0.003242  0.003242   \n",
       "4031  0.022484  0.022484  0.022484  0.800000   0.022484  0.022484  0.022484   \n",
       "\n",
       "           7         8         9     ...      7408      7409      7410  \\\n",
       "0      0.005139  0.005139  0.005139  ...  0.005139  0.005139  0.005139   \n",
       "1      0.002160  0.002160  0.002160  ...  0.002160  0.002160  0.002160   \n",
       "2      0.003785  0.003785  0.003785  ...  0.003785  0.003785  0.003785   \n",
       "3      0.003785  0.003785  0.003785  ...  0.003785  0.003785  0.003785   \n",
       "4      0.005960  0.005960  0.005960  ...  0.005960  0.005960  0.005960   \n",
       "5      0.000810  0.000810  0.000810  ...  0.000810  0.000810  0.000810   \n",
       "6      0.002430  0.002430  0.002430  ...  0.002430  0.002430  0.002430   \n",
       "7      0.004060  0.004060  0.004060  ...  0.004060  0.004060  0.004060   \n",
       "8      0.001079  0.001079  0.001079  ...  0.001079  0.001079  0.001079   \n",
       "9      0.001890  0.001890  0.001890  ...  0.001890  0.001890  0.001890   \n",
       "10     0.015269  0.015269  0.015269  ...  0.015269  0.015269  0.015269   \n",
       "11     0.558140  0.011675  0.011675  ...  0.011675  0.011675  0.011675   \n",
       "12     0.004055  0.004055  0.004055  ...  0.004055  0.004055  0.004055   \n",
       "13     0.004055  0.004055  0.004055  ...  0.004055  0.004055  0.004055   \n",
       "14     0.002972  0.002972  0.002972  ...  0.002972  0.002972  0.002972   \n",
       "15     0.001892  0.001892  0.001892  ...  0.001892  0.001892  0.001892   \n",
       "16     0.004054  0.004054  0.004054  ...  0.004054  0.004054  0.004054   \n",
       "17     0.017173  0.017173  0.017173  ...  0.017173  0.017173  0.017173   \n",
       "18     0.003241  0.003241  0.003241  ...  0.003241  0.003241  0.003241   \n",
       "19     0.004869  0.004869  0.004869  ...  0.004869  0.004869  0.004869   \n",
       "20     0.007321  0.007321  0.007321  ...  0.007321  0.007321  0.007321   \n",
       "21     0.002704  0.002704  0.002704  ...  0.002704  0.002704  0.002704   \n",
       "22     0.003513  0.003513  0.003513  ...  0.003513  0.003513  0.003513   \n",
       "23     0.002975  0.002975  0.002975  ...  0.002975  0.002975  0.002975   \n",
       "24     0.014436  0.014436  0.014436  ...  0.014436  0.014436  0.014436   \n",
       "25     0.006770  0.006770  0.006770  ...  0.006770  0.006770  0.006770   \n",
       "26     0.002160  0.002160  0.002160  ...  0.002160  0.002160  0.002160   \n",
       "27     0.003514  0.003514  0.003514  ...  0.003514  0.003514  0.003514   \n",
       "28     1.142857  0.002162  0.002162  ...  0.002162  0.002162  0.002162   \n",
       "29     0.004060  0.004060  0.004060  ...  0.004060  0.004060  0.004060   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "4002   0.003246  0.003246  0.003246  ...  0.003246  0.003246  0.003246   \n",
       "4003   0.002701  0.002701  0.002701  ...  0.002701  0.002701  0.002701   \n",
       "4004   0.001350  0.001350  0.001350  ...  0.001350  0.001350  0.001350   \n",
       "4005   0.004596  0.004596  0.004596  ...  0.004596  0.004596  0.004596   \n",
       "4006   0.002701  0.002701  0.002701  ...  0.002701  0.002701  0.002701   \n",
       "4007   0.003784  0.003784  0.003784  ...  0.003784  0.003784  0.003784   \n",
       "4008   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4009   0.008955  0.008955  0.008955  ...  0.008955  0.008955  0.008955   \n",
       "4010  12.000000  0.019970  0.019970  ...  0.019970  0.019970  0.019970   \n",
       "4011   0.002705  0.002705  0.002705  ...  0.002705  0.002705  0.002705   \n",
       "4012   0.028005  0.028005  0.028005  ...  0.028005  0.028005  0.028005   \n",
       "4013   0.004603  0.004603  0.004603  ...  0.004603  0.004603  0.004603   \n",
       "4014   0.005686  0.005686  0.005686  ...  0.005686  0.005686  0.005686   \n",
       "4015   0.015259  0.015259  0.015259  ...  0.015259  0.015259  0.015259   \n",
       "4016   0.002701  0.002701  0.002701  ...  0.002701  0.002701  0.002701   \n",
       "4017   0.012794  0.012794  0.012794  ...  0.012794  0.012794  0.012794   \n",
       "4018   0.001890  0.001890  0.001890  ...  0.001890  0.001890  0.001890   \n",
       "4019   0.006228  0.006228  0.006228  ...  0.006228  0.006228  0.006228   \n",
       "4020   0.008954  0.008954  0.008954  ...  0.008954  0.008954  0.008954   \n",
       "4021   0.004875  0.004875  0.004875  ...  0.004875  0.004875  0.004875   \n",
       "4022   0.008136  0.008136  0.008136  ...  0.008136  0.008136  0.008136   \n",
       "4023   0.004325  0.004325  0.004325  ...  0.004325  0.004325  0.004325   \n",
       "4024   0.615385  0.014426  0.014426  ...  0.014426  0.014426  0.014426   \n",
       "4025   0.003515  0.003515  0.003515  ...  0.003515  0.003515  0.003515   \n",
       "4026   0.014194  0.014194  0.014194  ...  0.014194  0.014194  0.014194   \n",
       "4027   0.484848  0.027179  0.027179  ...  0.027179  0.027179  0.027179   \n",
       "4028   0.004601  0.004601  0.004601  ...  0.004601  0.004601  0.004601   \n",
       "4029   0.004872  0.004872  0.004872  ...  0.004872  0.004872  0.004872   \n",
       "4030   0.003242  0.003242  0.003242  ...  0.003242  0.003242  0.003242   \n",
       "4031   0.022484  0.022484  0.022484  ...  0.022484  0.022484  0.022484   \n",
       "\n",
       "          7411      7412      7413      7414      7415      7416      7417  \n",
       "0     0.005139  0.005139  0.005139  0.005139  0.005139  0.005139  0.005139  \n",
       "1     0.002160  0.002160  0.002160  0.002160  0.002160  0.002160  0.002160  \n",
       "2     0.003785  0.003785  0.003785  0.003785  0.003785  0.003785  0.003785  \n",
       "3     0.003785  0.003785  0.003785  0.003785  0.003785  0.003785  0.003785  \n",
       "4     0.005960  0.005960  0.005960  0.005960  0.005960  0.005960  0.005960  \n",
       "5     0.000810  0.000810  0.000810  0.000810  0.000810  0.000810  0.000810  \n",
       "6     0.002430  0.002430  0.002430  0.002430  0.002430  0.002430  0.002430  \n",
       "7     0.004060  0.004060  0.004060  0.004060  0.004060  0.004060  0.004060  \n",
       "8     0.001079  0.001079  0.001079  0.001079  0.001079  0.001079  0.001079  \n",
       "9     0.001890  0.001890  0.001890  0.001890  0.001890  0.001890  0.001890  \n",
       "10    0.015269  0.015269  0.015269  0.015269  0.015269  0.015269  0.015269  \n",
       "11    0.011675  0.011675  0.011675  0.011675  0.011675  0.011675  0.011675  \n",
       "12    0.004055  0.004055  0.004055  0.004055  0.004055  0.004055  0.004055  \n",
       "13    0.004055  0.004055  0.004055  0.004055  0.004055  0.004055  0.004055  \n",
       "14    0.002972  0.002972  0.002972  0.002972  0.002972  0.002972  0.002972  \n",
       "15    0.001892  0.001892  0.001892  0.001892  0.001892  0.001892  0.001892  \n",
       "16    0.004054  0.004054  0.004054  0.004054  0.004054  0.004054  0.004054  \n",
       "17    0.017173  0.017173  0.017173  0.017173  0.017173  0.017173  0.017173  \n",
       "18    0.003241  0.003241  0.003241  0.003241  0.003241  0.003241  0.003241  \n",
       "19    0.004869  0.004869  0.004869  0.004869  0.004869  0.004869  0.004869  \n",
       "20    0.007321  0.007321  0.007321  0.007321  0.007321  0.007321  0.007321  \n",
       "21    0.002704  0.002704  0.002704  0.002704  0.002704  0.002704  0.002704  \n",
       "22    0.003513  0.003513  0.003513  0.003513  0.003513  0.003513  0.003513  \n",
       "23    0.002975  0.002975  0.002975  0.002975  0.002975  0.002975  0.002975  \n",
       "24    0.014436  0.014436  0.014436  0.014436  0.014436  0.014436  0.014436  \n",
       "25    0.006770  0.006770  0.006770  0.006770  0.006770  0.006770  0.006770  \n",
       "26    0.002160  0.002160  0.002160  0.002160  0.002160  0.002160  0.002160  \n",
       "27    0.003514  0.003514  0.003514  0.003514  0.003514  0.003514  0.003514  \n",
       "28    0.002162  0.002162  0.002162  0.002162  0.002162  0.002162  0.002162  \n",
       "29    0.004060  0.004060  0.004060  0.004060  0.004060  0.004060  0.004060  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4002  0.003246  0.003246  0.003246  0.003246  0.003246  0.003246  0.003246  \n",
       "4003  0.002701  0.002701  0.002701  0.002701  0.002701  0.002701  0.002701  \n",
       "4004  0.001350  0.001350  0.001350  0.001350  0.001350  0.001350  0.001350  \n",
       "4005  0.004596  0.004596  0.004596  0.004596  0.004596  0.004596  0.004596  \n",
       "4006  0.002701  0.002701  0.002701  0.002701  0.002701  0.002701  0.002701  \n",
       "4007  0.003784  0.003784  0.003784  0.003784  0.003784  0.003784  0.003784  \n",
       "4008  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4009  0.008955  0.008955  0.008955  0.008955  0.008955  0.008955  0.008955  \n",
       "4010  0.019970  0.019970  0.019970  0.019970  0.019970  0.019970  0.019970  \n",
       "4011  0.002705  0.002705  0.002705  0.002705  0.002705  0.002705  0.002705  \n",
       "4012  0.028005  0.028005  0.028005  0.028005  0.028005  0.028005  0.028005  \n",
       "4013  0.004603  0.004603  0.004603  0.004603  0.004603  0.004603  0.004603  \n",
       "4014  0.005686  0.005686  0.005686  0.005686  0.005686  0.005686  0.005686  \n",
       "4015  0.015259  0.015259  0.015259  0.015259  0.015259  0.015259  0.015259  \n",
       "4016  0.002701  0.002701  0.002701  0.002701  0.002701  0.002701  0.002701  \n",
       "4017  0.012794  0.012794  0.012794  0.012794  0.012794  0.012794  0.012794  \n",
       "4018  0.001890  0.001890  0.001890  0.001890  0.001890  0.001890  0.001890  \n",
       "4019  0.006228  0.006228  0.006228  0.006228  0.006228  0.006228  0.006228  \n",
       "4020  0.008954  0.008954  0.008954  0.008954  0.008954  0.008954  0.008954  \n",
       "4021  0.004875  0.004875  0.004875  0.004875  0.004875  0.004875  0.004875  \n",
       "4022  0.008136  0.008136  0.008136  0.008136  0.008136  0.008136  0.008136  \n",
       "4023  0.004325  0.004325  0.004325  0.004325  0.004325  0.004325  0.004325  \n",
       "4024  0.014426  0.014426  0.014426  0.014426  0.014426  0.014426  0.014426  \n",
       "4025  0.003515  0.003515  0.003515  0.003515  0.003515  0.003515  0.003515  \n",
       "4026  0.014194  0.014194  0.014194  0.014194  0.014194  0.014194  0.014194  \n",
       "4027  0.027179  0.027179  0.027179  0.027179  0.027179  0.027179  0.027179  \n",
       "4028  0.004601  0.004601  0.004601  0.004601  0.004601  0.004601  0.004601  \n",
       "4029  0.004872  0.004872  0.004872  0.004872  0.004872  0.004872  0.004872  \n",
       "4030  0.003242  0.003242  0.003242  0.003242  0.003242  0.003242  0.003242  \n",
       "4031  0.022484  0.022484  0.022484  0.022484  0.022484  0.022484  0.022484  \n",
       "\n",
       "[4032 rows x 7418 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_good_turing(x):\n",
    "    print(\"start\")\n",
    "    df_x = pd.DataFrame(x)\n",
    "    \n",
    "    df_x = df_x + 1 #add one as mentioned in paper\n",
    "    \n",
    "    print(\"iterating\")\n",
    "    res = []\n",
    "\n",
    "    for it, row in df_x.iterrows():\n",
    "        r_stars = {}\n",
    "        if it %500 == 0:\n",
    "            print(it, df_x.shape)\n",
    "            \n",
    "        vc = row.value_counts().to_dict()\n",
    "        for it in range(0, max(vc.keys())):\n",
    "            if it not in vc:\n",
    "                vc[it]= 0\n",
    "        #print(vc)\n",
    "        \n",
    "        for r in sorted(vc):\n",
    "            Nr_plus_1 = 0 if r+1 not in vc else vc[r+1]\n",
    "            Nr = vc[r] if r in vc else [vc[r_] for r_ in range(r, 0) if vc[r_1] > 0][0] # take next smallest value\n",
    "            Nr = Nr if Nr > 0 else 1\n",
    "            r_star = (r + 1) * (Nr_plus_1/Nr)\n",
    "            #print(\"r*\", r, Nr, Nr_plus_1, (Nr_plus_1/Nr) , r_star)\n",
    "            r_stars[r] = r_star\n",
    "        #print(vc, r_stars)\n",
    "        for it in range(0, max(r_stars.keys())):\n",
    "            if it not in r_stars:\n",
    "                r_stars[it]= 0\n",
    "        #print(vc)\n",
    "        \n",
    "        res.append(row.map(lambda n: r_stars[n]))\n",
    "      \n",
    "    df_res = pd.DataFrame(res)\n",
    "\n",
    "    return df_res\n",
    "\n",
    "text = [[1,0,1,0,1], [2,1,0,1,2], [5,0,0,1,0], [2,3,0,0,0]]\n",
    "apply_good_turing(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "iterating\n",
      "0 (4032, 7418)\n",
      "500 (4032, 7418)\n",
      "1000 (4032, 7418)\n",
      "1500 (4032, 7418)\n",
      "2000 (4032, 7418)\n",
      "2500 (4032, 7418)\n",
      "3000 (4032, 7418)\n",
      "3500 (4032, 7418)\n",
      "4000 (4032, 7418)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 188 tn= 194 fp= 30 fn= 36\n",
      "scoring= 0.8526785714285714\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7408)\n",
      "500 (4032, 7408)\n",
      "1000 (4032, 7408)\n",
      "1500 (4032, 7408)\n",
      "2000 (4032, 7408)\n",
      "2500 (4032, 7408)\n",
      "3000 (4032, 7408)\n",
      "3500 (4032, 7408)\n",
      "4000 (4032, 7408)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7408)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 183 tn= 188 fp= 36 fn= 41\n",
      "scoring= 0.828125\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7376)\n",
      "500 (4032, 7376)\n",
      "1000 (4032, 7376)\n",
      "1500 (4032, 7376)\n",
      "2000 (4032, 7376)\n",
      "2500 (4032, 7376)\n",
      "3000 (4032, 7376)\n",
      "3500 (4032, 7376)\n",
      "4000 (4032, 7376)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 197 tn= 185 fp= 39 fn= 27\n",
      "scoring= 0.8526785714285714\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7410)\n",
      "500 (4032, 7410)\n",
      "1000 (4032, 7410)\n",
      "1500 (4032, 7410)\n",
      "2000 (4032, 7410)\n",
      "2500 (4032, 7410)\n",
      "3000 (4032, 7410)\n",
      "3500 (4032, 7410)\n",
      "4000 (4032, 7410)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7410)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 191 tn= 198 fp= 26 fn= 33\n",
      "scoring= 0.8683035714285714\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7436)\n",
      "500 (4032, 7436)\n",
      "1000 (4032, 7436)\n",
      "1500 (4032, 7436)\n",
      "2000 (4032, 7436)\n",
      "2500 (4032, 7436)\n",
      "3000 (4032, 7436)\n",
      "3500 (4032, 7436)\n",
      "4000 (4032, 7436)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7436)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 195 tn= 192 fp= 32 fn= 29\n",
      "scoring= 0.8638392857142857\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7366)\n",
      "500 (4032, 7366)\n",
      "1000 (4032, 7366)\n",
      "1500 (4032, 7366)\n",
      "2000 (4032, 7366)\n",
      "2500 (4032, 7366)\n",
      "3000 (4032, 7366)\n",
      "3500 (4032, 7366)\n",
      "4000 (4032, 7366)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7366)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 188 tn= 179 fp= 45 fn= 36\n",
      "scoring= 0.8191964285714286\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7458)\n",
      "500 (4032, 7458)\n",
      "1000 (4032, 7458)\n",
      "1500 (4032, 7458)\n",
      "2000 (4032, 7458)\n",
      "2500 (4032, 7458)\n",
      "3000 (4032, 7458)\n",
      "3500 (4032, 7458)\n",
      "4000 (4032, 7458)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7458)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 182 tn= 186 fp= 38 fn= 42\n",
      "scoring= 0.8214285714285714\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7191)\n",
      "500 (4032, 7191)\n",
      "1000 (4032, 7191)\n",
      "1500 (4032, 7191)\n",
      "2000 (4032, 7191)\n",
      "2500 (4032, 7191)\n",
      "3000 (4032, 7191)\n",
      "3500 (4032, 7191)\n",
      "4000 (4032, 7191)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7191)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 190 tn= 189 fp= 35 fn= 34\n",
      "scoring= 0.8459821428571429\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7414)\n",
      "500 (4032, 7414)\n",
      "1000 (4032, 7414)\n",
      "1500 (4032, 7414)\n",
      "2000 (4032, 7414)\n",
      "2500 (4032, 7414)\n",
      "3000 (4032, 7414)\n",
      "3500 (4032, 7414)\n",
      "4000 (4032, 7414)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7414)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 195 tn= 187 fp= 37 fn= 29\n",
      "scoring= 0.8526785714285714\n",
      "start\n",
      "iterating\n",
      "0 (4032, 7356)\n",
      "500 (4032, 7356)\n",
      "1000 (4032, 7356)\n",
      "1500 (4032, 7356)\n",
      "2000 (4032, 7356)\n",
      "2500 (4032, 7356)\n",
      "3000 (4032, 7356)\n",
      "3500 (4032, 7356)\n",
      "4000 (4032, 7356)\n",
      "start\n",
      "iterating\n",
      "0 (448, 7356)\n",
      "tp= 189 tn= 185 fp= 39 fn= 35\n",
      "scoring= 0.8348214285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    gt_x_train = apply_good_turing(x_train[it])\n",
    "    gt_x_test = apply_good_turing(x_test[it])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    clf.fit(gt_x_train, y_train[it])\n",
    "    predicted = clf.predict(gt_x_test)\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 1898 tn= 1883 fp= 357 fn= 342\n",
      "scoring= 0.8439732142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_grams(tokens, n):\n",
    "    res = []\n",
    "    for it in range(0, len(tokens) -(n-1)):\n",
    "        res.append(\" \". join(tokens[it: it +n]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n",
      "4032 448 4032 448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "datasets = load_dataset(dataset_paths[1])\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=literal_eval)\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_train = dataset[0]\n",
    "    df_test = dataset[1]\n",
    "    df_train[\"tokens\"] = df_train.tokens.map(lambda tokens: str(create_n_grams(literal_eval(tokens), 2)))\n",
    "    df_test[\"tokens\"] = df_test.tokens.map(lambda tokens: str(create_n_grams(literal_eval(tokens), 2)))\n",
    "    \n",
    "    temp_train = vectorizer.fit_transform(df_train[\"tokens\"])\n",
    "    x_train.append(temp_train.toarray())\n",
    "    y_train.append(df_train.bool_rating.tolist())\n",
    "\n",
    "    temp_test = vectorizer.transform(df_test[\"tokens\"])\n",
    "    x_test.append(temp_test.toarray())\n",
    "    y_test.append(df_test.bool_rating.tolist())\n",
    "\n",
    "    print(len(x_train[-1]), len(x_test[-1]), len(y_train[-1]), len(y_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 217 tn= 224 fp= 0 fn= 7\n",
      "scoring= 0.984375\n",
      "tp= 219 tn= 220 fp= 4 fn= 5\n",
      "scoring= 0.9799107142857143\n",
      "tp= 218 tn= 220 fp= 4 fn= 6\n",
      "scoring= 0.9776785714285714\n",
      "tp= 217 tn= 223 fp= 1 fn= 7\n",
      "scoring= 0.9821428571428571\n",
      "tp= 218 tn= 223 fp= 1 fn= 6\n",
      "scoring= 0.984375\n",
      "tp= 218 tn= 221 fp= 3 fn= 6\n",
      "scoring= 0.9799107142857143\n",
      "tp= 220 tn= 220 fp= 4 fn= 4\n",
      "scoring= 0.9821428571428571\n",
      "tp= 215 tn= 222 fp= 2 fn= 9\n",
      "scoring= 0.9754464285714286\n",
      "tp= 216 tn= 222 fp= 2 fn= 8\n",
      "scoring= 0.9776785714285714\n",
      "tp= 220 tn= 219 fp= 5 fn= 4\n",
      "scoring= 0.9799107142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "tps, tns, fps, fns = [],[],[],[]\n",
    "\n",
    "for it,_ in enumerate(x_train):\n",
    "    clf.fit(x_train[it], y_train[it])\n",
    "    predicted = clf.predict(x_test[it])\n",
    "\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for itx, x in enumerate(predicted):\n",
    "        if x and y_test[it][itx]:\n",
    "            tp += 1\n",
    "        elif x and not y_test[it][itx]:\n",
    "            fp += 1\n",
    "        elif not x and y_test[it][itx]:\n",
    "            fn += 1\n",
    "        elif not x and not y_test[it][itx]:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp=\", tp,\"tn=\", tn,\"fp=\", fp,\"fn=\", fn)\n",
    "    print(\"scoring=\", sum([tp, tn])/sum([tp, tn, fp, fn]))\n",
    "    \n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp= 2178 tn= 2214 fp= 26 fn= 62\n",
      "scoring= 0.9803571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"tp=\", sum(tps),\"tn=\", sum(tns),\"fp=\", sum(fps),\"fn=\", sum(fns))\n",
    "print(\"scoring=\", sum([sum(tps), sum(tns)])/sum([sum(tps), sum(tns), sum(fps), sum(fns)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
